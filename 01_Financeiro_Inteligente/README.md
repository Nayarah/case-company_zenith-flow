#  M√≥dulo 01: Financeiro Inteligente - Automa√ß√£o e ETL


## üí° Objetivo do M√≥dulo
Este m√≥dulo demonstra a prova de conceito do ecossistema ZenithFlow, criando um pipeline end-to-end de dados financeiros com:

- Extra√ß√£o autom√°tica do GitHub

- Transforma√ß√£o com Power Query (Linguagem M)

- Visualiza√ß√£o em Power BI

- Automa√ß√£o de relat√≥rios via VBA e Power Automate

O objetivo √© automatizar o fechamento mensal de m√∫ltiplas filiais, consolidando receitas e despesas e gerando saldos e acumulados.

<br>


## ‚öôÔ∏è Tecnologias e Ferramentas
| Categoria | Ferramenta | Uso no Projeto |
| :--- | :--- | :--- |
| **ETL e Modelagem** | Excel Power Query (Linguagem M) | Extra√ß√£o dos arquivos via links p√∫blicos do GitHub, limpeza e modelagem de dados. |
| **Automa√ß√£o** | VBA (Visual Basic for Applications) | Automa√ß√£o do fluxo de trabalho: Atualiza√ß√£o das consultas, cria√ß√£o de PDF e distribui√ß√£o por e-mail. |
| **Orquestra√ß√£o** | Power Automate / Agendador de Tarefas | Possibilita execu√ß√£o autom√°tica em hor√°rios pr√©-definidos. |
| **Visualiza√ß√£o** | Powe BI | Visualiza√ß√£o do relat√≥rio e cria√ß√£o de insights do neg√≥cio com medidas de time intelligence.
| **Fonte de Dados** | GitHub | Reposit√≥rio remoto para leitura via Web.Contents(), simulando um ambiente de produ√ß√£o com SharePoint ou DataLake. |

---

## üìÅ Estrutura do Projeto

### Arquivos de Entrada (RAW Data)
Os arquivos de entrada s√£o fict√≠cios e simulam um **data lake financeiro**, frequentemente despadronizados e provenientes de diversas fontes, exigindo o tratamento robusto do Power Query.
* **`Dados/Despesas_Filiais/`:** Cont√©m registros de custos operacionais por filial e compet√™ncia.
* **`Dados/Receitas_Filiais/`:** Cont√©m registros de vendas e receitas de multiplos canais por filial e compet√™ncia.
* **`Dados/Links_Financeiro.xlsx`:** Um arquivo de metadados que cont√©m as colunas Tipo e Filial. O Power Query utiliza as informa√ß√µes desta tabela para construir dinamicamente os caminhos de acesso aos dados brutos no GitHub (simulando uma tabela de mapeamento)

### Processamento
* **`Dados/01_Financeiro_Mestre_ETL.xlsx`:** Como o nome sugere, um arquivo mestre que cont√©m todo o c√≥digo M e camadas deste pipeline. O star schema (modelo Fato/Dimens√£o) √© implementado na camada GL dentro deste arquivo.As camadas est√£o melhor descritos abaixo. Esta centraliza√ß√£o do c√≥digo M visa a otimiza√ß√£o da manuten√ß√£o e auditoria do pipeline sendo uma fonte √∫nica do fluxo dos dados.

### Sa√≠da (Output)
* **`Relatorios/01_Financeiro_Modelo_Dados.pbix`:** Cont√©m a camada Gold conectada via Power Query para visualiza√ß√£o do relat√≥rio e cria√ß√£o de insights do neg√≥cio.

* **Relat√≥rio PDF:** Arquivo gerado automaticamente com o *snapshot* do Dashboard.

```

01_Financeiro_Inteligente/
‚îÇ
‚îú‚îÄ‚îÄ Dados/
‚îÇ   ‚îú‚îÄ‚îÄ Despesas_Filiais/
‚îÇ   ‚îú‚îÄ‚îÄ Receitas_Filiais/
‚îÇ   ‚îú‚îÄ‚îÄ Financeiro_Mestre_ETL.xlsx  
‚îÇ   ‚îî‚îÄ‚îÄ Links_Financeiro.xlsx
‚îÇ
‚îú‚îÄ‚îÄ Relatorios/
‚îÇ   ‚îú‚îÄ‚îÄ 01_Financeiro_Modelo_Dados.xlsx
‚îÇ   ‚îî‚îÄ‚îÄ Dashboard_Financeiro.pdf
‚îî‚îÄ‚îÄ README.md

```

---

# üß© Estrutura Modular ‚Äî Pipeline ETL
## Extra√ß√£o (E)  
Nesta etapa temos a camada Bronze na consulta `_BZ_Financeiro_Consolidado` do arquivo mestre, que utiliza as fun√ß√µes abaixo para obten√ß√£o de arquivos CSV, faz a combina√ß√£o destes arquivos, normaliza e cria uma chave match com os caminhos dos arquivos utilizando `Table.NestedJoin`, para enriquecer com as colunas tipo e filial obtendo esta informa√ß√£o de forma confi√°vel da origem dos arquivos.

### üîß**fnGetFolderContent**
  * A fun√ß√£o customizada: fnGetFolderContent foi Criada para possibiliar a obten√ß√£o autom√°tica de qualquer arquivo inserido na pasta compartilhada do GitHub, staging area, por URL API REST via Web.Contents()


>üîπ C√≥digo M da fun√ß√£o na se√ß√£o colaps√°vel abaixo.

<details> <summary>fnGetFolderContent (Power Query)</summary>

```m

// Fun√ß√£o customizada: fnGetFolderContent - Criada para possibiliar ler todos os arquivos de uma pasta por URL API REST via Web.Contents()
(caminho as text, BaseApiUrl as text, Branch as text) as table =>
let
    // 1. Constr√≥i a URL da API da pasta, usando os par√¢metros de entrada
    FullUrl = BaseApiUrl & caminho & "?ref=" & Branch,  

    // 2. L√™ o BIN√ÅRIO da API (Web.Contents)
    Source = Web.Contents(FullUrl),

    // 3. For√ßa o Power Query a tratar esta fonte como "P√∫blica"
    Source_API_Public = Value.ReplaceMetadata(Source, [IsDataSource = true, PrivacySetting = "Public"]),

    // 4. Converte o bin√°rio para JSON.
    JsonTable = Json.Document(Source_API_Public),  

    // 5. Transforma a lista de registros JSON em uma tabela
    TableContent = Table.FromList(JsonTable, Splitter.SplitByNothing(), null, null, ExtraValues.Error),
    

    // 6. Expande para obter os links de download dos CSVs
    ExpandRecords = Table.ExpandRecordColumn(TableContent, "Column1", {"name", "download_url"}, {"NomeArquivo", "FilePath"}),
    
    // 7. Garante que apenas CSVs sejam processados e adiciona o caminho original
    FilterCSV = Table.SelectRows(ExpandRecords, each Text.EndsWith([NomeArquivo], ".csv")),
    AddCaminhoStaging = Table.AddColumn(FilterCSV, "Origem", each caminho, type text)
in
    AddCaminhoStaging

```
</details>

<br>

### üîß**fxBZ_ReadCSV**
  * Fun√ß√£o Customizada: fxBZ_ReadCSV - fxBZ_ReadCSV: Fun√ß√£o de Tratamento de Schema Drift e Tipagem Resiliente.

>üîπ C√≥digo M da fun√ß√£o na se√ß√£o colaps√°vel abaixo.

<details><summary>fxBZ_ReadCSV</summary>

```m

/*Fun√ß√£o Customizada: fxBZ_ReadCSV - Criada para ler arquivos CSVs em pastas 
sem e apropriar do modelo criado pelo Power Query a partir do primeiro arquivo 
e normalizar as colunas dos arquivos CSV
*/

(filePath as text) as table =>
let
    // 1) Ler CSV local ou remoto
    Fonte =
        if Text.StartsWith(filePath, "http", Comparer.OrdinalIgnoreCase) then
            Csv.Document(
                Web.Contents(filePath),
                [Delimiter = ",", Encoding = 65001, QuoteStyle = QuoteStyle.Csv]
            )
        else
            Csv.Document(
                File.Contents(filePath),
                [Delimiter = ",", Encoding = 65001, QuoteStyle = QuoteStyle.Csv]
            ),

    // 2) Cabe√ßalhos
    Promoted = Table.PromoteHeaders(Fonte, [PromoteAllScalars = true]),

    // 3) Detectar ‚Äúreceita‚Äù vs ‚Äúdespesa‚Äù pelos nomes originais
    Cols = Table.ColumnNames(Promoted),
    IsDespesa = List.Contains(Cols, "Tipo de Despesa"),
    IsReceita = List.Contains(Cols, "Receita"),

    // 4) Normalizar: Data, Categoria, Valor, Descri√ß√£o
    NormalizedRaw =
        if IsDespesa then
            // Despesa: renomeia "Tipo de Despesa" -> "Categoria"
            Table.RenameColumns(Promoted, {{"Tipo de Despesa", "Categoria"}}, MissingField.Ignore)
        else if IsReceita then
            // Receita: Renomeia "Receita" -> "Valor", "Canal de Venda" -> "Descri√ß√£o"
            Table.RenameColumns(
                Promoted,
                {{"Receita", "Valor"}, {"Canal de Venda", "Descri√ß√£o"}},
                MissingField.Ignore
            )
        else
            Promoted,

    // 5) Garantir que TODAS as 4 colunas existam (se faltar, cria nula)
    EnsureData = if not List.Contains(Table.ColumnNames(NormalizedRaw), "Data")
                    then Table.AddColumn(NormalizedRaw, "Data", each null, type any) else NormalizedRaw,
    EnsureCategoria = if not List.Contains(Table.ColumnNames(EnsureData), "Categoria")
                    then Table.AddColumn(EnsureData, "Categoria", each null, type text) else EnsureData,
    EnsureValor = if not List.Contains(Table.ColumnNames(EnsureCategoria), "Valor")
                    then Table.AddColumn(EnsureCategoria, "Valor", each null, type number) else EnsureCategoria,
    EnsureDescricao = if not List.Contains(Table.ColumnNames(EnsureValor), "Descri√ß√£o")
                    then Table.AddColumn(EnsureValor, "Descri√ß√£o", each null, type text) else EnsureValor,

    // 6) Tratar Data de forma resiliente (tenta converter; se falhar, deixa null)
    DataFixed = Table.TransformColumns(
        EnsureDescricao,
        {{"Data", each try DateTime.FromText(Text.Trim(Text.From(_)), "pt-BR") otherwise null, type datetime}}
    ),

    // 7) Tipa as colunas padronizadas
    Typed = Table.TransformColumnTypes(
        DataFixed,
        {{"Data", type datetime}, {"Categoria", type text}, {"Valor", type number}, {"Descri√ß√£o", type text}},
        "pt-BR"
    )
in
    Typed
```
</details>

<br>

## **Transforma√ß√£o (T) e Enriquecimento:**
A consulta `SL_Financeiro` do arquivo mestre √© a camada Silver deste projeto onde temos a consulta da camada bronze da etapa anterior e h√° a tipagem dos dados e o enriquecimento das colunas Saldo, M√™s e Ano.

A consulta `GL_Fato_Financeiro`do arquivo mestre √© a camada Gold onde temos a tabela fato da etapa Silver resumida e a cria√ß√£o das Foreign Key para as dimens√µes originadas desta consulta e s√£o elas `DimFilial`, `DimCategoria`, `DimTipo` e `Calend√°rio` tamb√©m contidas no arquivo mestre.


## **Carga (L):**
Conex√£o direta do modelo de dados da etapa Gold com a tabela fato, dimens√µes e calend√°rio no Power BI via Power Query.




##  üíª Automa√ß√£o VBA ‚Äî Atualiza√ß√£o e Distribui√ß√£o

Macro Run_Update() atualiza todas as consultas, gera PDF do Dashboard e prepara e-mail:
```
Sub Run_Update()
    ThisWorkbook.RefreshAll
    Sheets("Dashboard").ExportAsFixedFormat Type:=xlTypePDF, Filename:=ThisWorkbook.Path & "\Relatorio_Financeiro.pdf"
    ' Abre e-mail com PDF anexado
End Sub

```



## üöÄ Guia de Execu√ß√£o (*Quick Start*)

Este m√≥dulo foi projetado para simular um processo real de fechamento financeiro automatizado, com um clique (ou execu√ß√£o agendada via Power Automate / Task Scheduler).

### Pr√©-requisitos
* Microsoft Excel (com Power Query e suporte a VBA).
* Conex√£o com a internet (para leitura dos arquivos hospedados no GitHub).
* Configura√ß√£o de seguran√ßa habilitando:
  - Conte√∫do externo (consultas da Web)
  - Execu√ß√£o de Macros (VBA)

### Instru√ß√µes:
1. **Abrir Arquivo:** Inicie a execu√ß√£o abrindo o arquivo 01_Financeiro_Modelo_Dados.pbix no Power BI Desktop. Este arquivo est√° configurado para conectar-se ao Financeiro_Mestre_ETL.xlsx, que cont√©m todo o pipeline de dados.

2. **Atualizar:** Clique em Atualizar. O Power BI executar√° o pipeline completo de forma encadeada:

- BZ: L√™ metadados e baixa CSVs.

- SL: Limpa e enriquece.

- GD: Cria as tabelas Fato e Dimens√µes.

Visualiza√ß√£o: O Modelo Dimensional (Schema Estrela) estar√° pronto para uso.



---


### ü™∂ Autor

üë©‚Äçüíª Nayara Almeida

[üìé LinkedIn](https://www.linkedin.com/in/nayara-falmeida/) | [GitHub](https://github.com/Nayarah)
